{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import timm\n",
    "from torch.utils.data import Subset\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# BaseLine 코드로 주어진 dataset.py model.py, loss.py를 Import 합니다.\n",
    "from dataset import MaskBaseDataset, BaseAugmentation\n",
    "from model import *\n",
    "from loss import create_criterion\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    동일한 조건으로 학습을 할 때, 동일한 결과를 얻기 위해 seed를 고정시킵니다.\n",
    "    \n",
    "    Args:\n",
    "        seed: seed 정수값\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- parameters\n",
    "img_root = '/opt/ml/input/data/train'\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "num_classes = 18\n",
    "\n",
    "num_epochs = 100  # 학습할 epoch의 수\n",
    "log_interval = 80\n",
    "\n",
    "lr = 1e-4\n",
    "lr_decay_step = 10\n",
    "criterion_name = 'cross_entropy' # loss의 이름\n",
    "\n",
    "train_log_interval = 20  # logging할 iteration의 주기\n",
    "name = \"02_model_results\"  # 결과를 저장하는 폴더의 이름\n",
    "\n",
    "# -- settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataloader(dataset, train_idx, valid_idx, batch_size, num_workers):\n",
    "    # 인자로 전달받은 dataset에서 train_idx에 해당하는 Subset 추출\n",
    "    train_set = torch.utils.data.Subset(dataset,\n",
    "                                        indices=train_idx)\n",
    "    # 인자로 전달받은 dataset에서 valid_idx에 해당하는 Subset 추출\n",
    "    val_set   = torch.utils.data.Subset(dataset,\n",
    "                                        indices=valid_idx)\n",
    "    \n",
    "    # 추출된 Train Subset으로 DataLoader 생성\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    # 추출된 Valid Subset으로 DataLoader 생성\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # 생성한 DataLoader 반환\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_root = '/opt/ml/input/data/train/images'\n",
    "\n",
    "dataset = MaskBaseDataset(img_root)\n",
    "\n",
    "transform = BaseAugmentation(\n",
    "    resize=[128, 96],\n",
    "    mean=dataset.mean,\n",
    "    std=dataset.std,\n",
    ")\n",
    "\n",
    "dataset.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "from dataset import TestDataset\n",
    "\n",
    "test_img_root = '/opt/ml/input/data/eval'   \n",
    "# public, private 테스트셋이 존재하니 각각의 예측결과를 저장합니다.\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_img_root, 'info.csv'))\n",
    "image_dir = os.path.join(test_img_root, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "test_dataset = TestDataset(image_paths, resize=(128, 96))\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(device)\n",
    "model.load_state_dict(torch.load(f\"ck/best.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    labels = []\n",
    "    for images in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Test Time Augmentation\n",
    "        age_outs, gender_outs, mask_outs = model(images)\n",
    "                \n",
    "        age_preds = torch.argmax(age_outs, dim=-1).item()\n",
    "        gender_preds = torch.argmax(gender_outs, dim=-1).item()\n",
    "        mask_preds = torch.argmax(mask_outs, dim=-1).item()\n",
    "        \n",
    "        label = dataset.encode_multi_class(mask_preds, gender_preds, age_preds)\n",
    "        labels.append(label)\n",
    "\n",
    "submission['ans'] = labels\n",
    "submission.to_csv('submission(15x5).csv', index=False)\n",
    "\n",
    "print(\"submission save done\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
