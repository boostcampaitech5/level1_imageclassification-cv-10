{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from importlib import import_module\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "from enum import Enum\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    data_dir = '/opt/ml/input/data/train'  \n",
    "    img_dir = f'{data_dir}/images'\n",
    "    df_path = f'{data_dir}/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = cfg()\n",
    "data_dir = cfg.data_dir\n",
    "img_dir = cfg.img_dir\n",
    "df_path = cfg.df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = (0.55800916, 0.51224077, 0.47767341), (0.21817792, 0.23804603, 0.25183411)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 마스크 여부, 성별, 나이를 mapping할 클래스를 생성합니다.\n",
    "\n",
    "class MaskLabels(int, Enum):\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "\n",
    "class GenderLabels(int, Enum):\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return cls.MALE\n",
    "        elif value == \"female\":\n",
    "            return cls.FEMALE\n",
    "        else:\n",
    "            raise ValueError(f\"Gender value should be either 'male' or 'female', {value}\")\n",
    "\n",
    "\n",
    "class AgeLabels(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(cls, value: str) -> int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Age value should be numeric, {value}\")\n",
    "\n",
    "        if value < 30:\n",
    "            return cls.YOUNG\n",
    "        elif value < 60:\n",
    "            return cls.MIDDLE\n",
    "        else:\n",
    "            return cls.OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskBaseDataset(data.Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1\": MaskLabels.MASK,\n",
    "        \"mask2\": MaskLabels.MASK,\n",
    "        \"mask3\": MaskLabels.MASK,\n",
    "        \"mask4\": MaskLabels.MASK,\n",
    "        \"mask5\": MaskLabels.MASK,\n",
    "        \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL\n",
    "    }\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, img_dir, mean, std, transform=None):\n",
    "        \"\"\"\n",
    "        MaskBaseDataset을 initialize 합니다.\n",
    "\n",
    "        Args:\n",
    "            img_dir: 학습 이미지 폴더의 root directory 입니다.\n",
    "            transform: Augmentation을 하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transform = transform\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"\n",
    "        transform 함수를 설정하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "    def setup(self):\n",
    "        \"\"\"\n",
    "        image의 경로와 각 이미지들의 label을 계산하여 저장해두는 함수입니다.\n",
    "        \"\"\"\n",
    "        profiles = os.listdir(self.img_dir)\n",
    "        for profile in profiles:\n",
    "            if profile.startswith(\".\"):  # \".\" 로 시작하는 파일은 무시합니다\n",
    "                continue\n",
    "\n",
    "            img_folder = os.path.join(self.img_dir, profile)\n",
    "            for file_name in os.listdir(img_folder):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(self.img_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                mask_label = self._file_names[_file_name]\n",
    "\n",
    "                id, gender, race, age = profile.split(\"_\")\n",
    "                gender_label = GenderLabels.from_str(gender)\n",
    "                age_label = AgeLabels.from_number(age)\n",
    "\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터를 불러오는 함수입니다. \n",
    "        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n",
    "        \n",
    "        Args:\n",
    "            index: 불러올 데이터의 인덱스값입니다.\n",
    "        \"\"\"\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = mask_label * 6 + gender_label * 3 + age_label\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "def get_transforms(need=('train', 'val'), img_size=(512, 384), mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)):\n",
    "    \"\"\"\n",
    "    train 혹은 validation의 augmentation 함수를 정의합니다. train은 데이터에 많은 변형을 주어야하지만, validation에는 최소한의 전처리만 주어져야합니다.\n",
    "    \n",
    "    Args:\n",
    "        need: 'train', 혹은 'val' 혹은 둘 다에 대한 augmentation 함수를 얻을 건지에 대한 옵션입니다.\n",
    "        img_size: Augmentation 이후 얻을 이미지 사이즈입니다.\n",
    "        mean: 이미지를 Normalize할 때 사용될 RGB 평균값입니다.\n",
    "        std: 이미지를 Normalize할 때 사용될 RGB 표준편차입니다.\n",
    "\n",
    "    Returns:\n",
    "        transformations: Augmentation 함수들이 저장된 dictionary 입니다. transformations['train']은 train 데이터에 대한 augmentation 함수가 있습니다.\n",
    "    \"\"\"\n",
    "    transformations = {}\n",
    "    if 'train' in need:\n",
    "        transformations['train'] = Compose([\n",
    "            Resize(img_size[0], img_size[1], p=1.0),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            GaussNoise(p=0.5),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    if 'val' in need:\n",
    "        transformations['val'] = Compose([\n",
    "            Resize(img_size[0], img_size[1]),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    return transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정의한 Augmentation 함수와 Dataset 클래스 객체를 생성합니다.\n",
    "transform = get_transforms(mean=mean, std=std)\n",
    "\n",
    "dataset = MaskBaseDataset(\n",
    "    img_dir=img_dir,\n",
    "    mean=mean,\n",
    "    std=std\n",
    ")\n",
    "\n",
    "# train dataset과 validation dataset을 8:2 비율로 나눕니다.\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# 각 dataset에 augmentation 함수를 설정합니다.\n",
    "train_dataset.dataset.set_transform(transform['train'])\n",
    "val_dataset.dataset.set_transform(transform['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /opt/conda/lib/python3.8/site-packages (0.6.13)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from timm) (5.3.1)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.8/site-packages (from timm) (0.13.4)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm) (0.8.2)\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.8/site-packages (from timm) (1.7.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (4.51.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (21.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (2.24.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (1.20.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub->timm) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (2020.12.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "m = timm.create_model('efficientnetv2_m', num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/8\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes=3, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
    "\n",
    "\n",
    "# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self, classes=3, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n",
    "        return 1 - f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_criterion_entrypoints = {\n",
    "    'cross_entropy': nn.CrossEntropyLoss,\n",
    "    'focal': FocalLoss,\n",
    "    'label_smoothing': LabelSmoothingLoss,\n",
    "    'f1': F1Loss\n",
    "}\n",
    "\n",
    "\n",
    "def criterion_entrypoint(criterion_name):\n",
    "    return _criterion_entrypoints[criterion_name]\n",
    "\n",
    "\n",
    "def is_criterion(criterion_name):\n",
    "    return criterion_name in _criterion_entrypoints\n",
    "\n",
    "\n",
    "def create_criterion(criterion_name, **kwargs):\n",
    "    if is_criterion(criterion_name):\n",
    "        create_fn = criterion_entrypoint(criterion_name)\n",
    "        criterion = create_fn(**kwargs)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown loss (%s)' % criterion_name)\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seed_everything(seed):\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.backends.cudnn.benchmark = False\n",
    "#     np.random.seed(seed)\n",
    "#     random.seed(seed)\n",
    "\n",
    "# def get_lr(optimizer):\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         return param_group['lr']\n",
    "    \n",
    "# def increment_path(path, exist_ok=False):\n",
    "#     \"\"\" Automatically increment path, i.e. runs/exp --> runs/exp0, runs/exp1 etc.\n",
    "\n",
    "#     Args:\n",
    "#         path (str or pathlib.Path): f\"{model_dir}/{args.name}\".\n",
    "#         exist_ok (bool): whether increment path (increment if False).\n",
    "#     \"\"\"\n",
    "#     path = Path(path)\n",
    "#     if (path.exists() and exist_ok) or (not path.exists()):\n",
    "#         return str(path)\n",
    "#     else:\n",
    "#         dirs = glob.glob(f\"{path}*\")\n",
    "#         matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n",
    "#         i = [int(m.groups()[0]) for m in matches if m]\n",
    "#         n = max(i) + 1 if i else 2\n",
    "#         return f\"{path}{n}\"\n",
    "\n",
    "    \n",
    "# def train(data_dir, model_dir, args):\n",
    "#     seed_everything(args.seed)\n",
    "\n",
    "#     save_dir = increment_path(os.path.join(model_dir, args.name))\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "#     print('model save path',save_dir)\n",
    "\n",
    "#     # -- settings\n",
    "#     use_cuda = torch.cuda.is_available()\n",
    "#     device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "#     # -- dataset\n",
    "#     dataset_module = getattr(import_module(\"dataset\"), args.dataset)  # default: MaskBaseDataset\n",
    "#     dataset = dataset_module(\n",
    "#         data_dir=data_dir, transform=My_transform('train')\n",
    "#     )\n",
    "\n",
    "#     # -- data_loader\n",
    "#     train_set, val_set = dataset.split_dataset()\n",
    "#     print('train data 개수:',len(train_set))\n",
    "#     print('val data 개수:',len(val_set))\n",
    "\n",
    "#     train_loader = DataLoader(\n",
    "#         train_set,\n",
    "#         batch_size=args.batch_size,\n",
    "#         num_workers=2,\n",
    "#         shuffle=True,\n",
    "#         pin_memory=use_cuda,\n",
    "#         drop_last=False,\n",
    "#     )\n",
    "\n",
    "#     val_loader = DataLoader(\n",
    "#         val_set,\n",
    "#         batch_size=args.valid_batch_size,\n",
    "#         num_workers=2,\n",
    "#         shuffle=False,\n",
    "#         pin_memory=use_cuda,\n",
    "#         drop_last=False,\n",
    "#     )\n",
    "\n",
    "#     # -- model\n",
    "#     model = m.to(device)\n",
    "#     model = torch.nn.DataParallel(model)\n",
    "# #     model = Multi_ModelClassification()\n",
    "# #     path = os.path.join('/opt/ml/code/baseline/v2/model/exp4', 'last.pth')\n",
    "# #     model.load_state_dict(torch.load(path, map_location=device))\n",
    "# #     model = torch.nn.DataParallel(model)\n",
    "\n",
    "#     # -- loss & metric\n",
    "#     criterion = create_criterion(args.criterion)  # default: cross_entropy\n",
    "#     opt_module = getattr(import_module(\"torch.optim\"), args.optimizer)  # default: SGD\n",
    "#     optimizer = opt_module(\n",
    "#         filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#         lr=args.lr,\n",
    "#     )\n",
    "#     print(optimizer)\n",
    "#     scheduler = StepLR(optimizer, args.lr_decay_step, gamma=0.5)\n",
    "\n",
    "#     age_best_val_acc,gender_best_val_acc,mask_best_val_acc=0,0,0\n",
    "#     age_best_val_loss,gender_best_val_loss,mask_best_val_loss=np.inf,np.inf,np.inf\n",
    "#     for epoch in range(args.epochs):\n",
    "#         # train loop\n",
    "#         model.train()\n",
    "#         loss_value = 0\n",
    "#         age_loss_value,gender_loss_value,mask_loss_value=0,0,0\n",
    "#         age_matches,gender_matches,mask_matches = 0,0,0\n",
    "#         for idx, train_batch in enumerate(train_loader):\n",
    "#             inputs,age_label,gender_label,mask_label=train_batch\n",
    "#             inputs = inputs.to(device)\n",
    "#             age_label = age_label.to(device)\n",
    "#             gender_label = gender_label.to(device)\n",
    "#             mask_label = mask_label.to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             age_outs, gender_outs, mask_outs = model(inputs)\n",
    "            \n",
    "#             age_preds = torch.argmax(age_outs, dim=-1)\n",
    "#             age_loss = criterion(age_outs, age_label)\n",
    "            \n",
    "#             gender_preds = torch.argmax(gender_outs, dim=-1)\n",
    "#             gender_loss = criterion(gender_outs, gender_label)\n",
    "            \n",
    "#             mask_preds = torch.argmax(mask_outs, dim=-1)\n",
    "#             mask_loss = criterion(mask_outs, mask_label)\n",
    "#             # loss balancing (이렇게 주는게 맞나)\n",
    "#             loss = 0.5*age_loss+0.25*gender_loss+0.25*mask_loss\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             loss_value += loss.item()\n",
    "           \n",
    "#             age_loss_value+=age_loss.item()\n",
    "#             gender_loss_value+=gender_loss.item()\n",
    "#             mask_loss_value+=mask_loss.item()\n",
    "            \n",
    "#             age_matches += (age_preds == age_label).sum().item()\n",
    "#             gender_matches += (gender_preds == gender_label).sum().item()\n",
    "#             mask_matches += (mask_preds == mask_label).sum().item()\n",
    "#             if (idx + 1) % args.log_interval == 0:\n",
    "#                 age_train_loss = age_loss_value / args.log_interval\n",
    "#                 age_train_acc = age_matches / args.batch_size / args.log_interval\n",
    "#                 gender_train_loss = gender_loss_value / args.log_interval\n",
    "#                 gender_train_acc = gender_matches / args.batch_size / args.log_interval\n",
    "#                 mask_train_loss = mask_loss_value / args.log_interval\n",
    "#                 mask_train_acc = mask_matches / args.batch_size / args.log_interval\n",
    "#                 total_loss = loss_value / args.log_interval\n",
    "#                 current_lr = get_lr(optimizer)\n",
    "#                 print(\n",
    "#                     f\"Epoch[{epoch}/{args.epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "#                     f\"age training loss {age_train_loss:4.4} || training accuracy {age_train_acc:4.2%} || lr {current_lr}\"\n",
    "#                 )\n",
    "#                 print(\n",
    "#                     f\"Epoch[{epoch}/{args.epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "#                     f\"gender training loss {gender_train_loss:4.4} || training accuracy {gender_train_acc:4.2%} || lr {current_lr}\"\n",
    "#                 )\n",
    "#                 print(\n",
    "#                     f\"Epoch[{epoch}/{args.epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "#                     f\"mask training loss {mask_train_loss:4.4} || training accuracy {mask_train_acc:4.2%} || lr {current_lr}\"\n",
    "#                 )\n",
    "\n",
    "#                 loss_value = 0\n",
    "#                 age_matches,gender_matches,mask_matches = 0,0,0\n",
    "\n",
    "#         scheduler.step()\n",
    "#         wandb.log({'total_loss': total_loss, 'epoch': epoch})\n",
    "#         wandb.log({'age_train_accuracy': age_train_acc, 'age_train_loss': age_train_loss,'epoch': epoch})\n",
    "#         wandb.log({'gender_train_accuracy': gender_train_acc, 'gender_train_loss': gender_train_loss,'epoch': epoch})\n",
    "#         wandb.log({'mask_train_accuracy': mask_train_acc, 'mask_train_loss': mask_train_loss,'epoch': epoch})\n",
    "\n",
    "#         # val loop\n",
    "#         with torch.no_grad():\n",
    "#             print(\"Calculating validation results...\")\n",
    "#             model.eval()\n",
    "#             age_val_loss_items,gender_val_loss_items,mask_val_loss_items = [],[],[]\n",
    "#             age_val_acc_items,gender_val_acc_items,mask_val_acc_items = [],[],[]\n",
    "#             figure = None\n",
    "#             for val_batch in val_loader:\n",
    "#                 inputs,age_label,gender_label,mask_label=val_batch\n",
    "#                 inputs = inputs.to(device)\n",
    "#                 age_label = age_label.to(device)\n",
    "#                 gender_label = gender_label.to(device)\n",
    "#                 mask_label = mask_label.to(device)\n",
    "                \n",
    "#                 age_outs, gender_outs, mask_outs = model(inputs)\n",
    "#                 age_preds = torch.argmax(age_outs, dim=-1)\n",
    "#                 age_loss = criterion(age_outs, age_label).item()\n",
    "#                 gender_preds = torch.argmax(gender_outs, dim=-1)\n",
    "#                 gender_loss = criterion(gender_outs, gender_label).item()\n",
    "#                 mask_preds = torch.argmax(mask_outs, dim=-1)\n",
    "#                 mask_loss = criterion(mask_outs, mask_label).item()\n",
    "                \n",
    "#                 age_matches = (age_preds == age_label).sum().item()\n",
    "#                 gender_matches = (gender_preds == gender_label).sum().item()\n",
    "#                 mask_matches = (mask_preds == mask_label).sum().item()\n",
    "\n",
    "\n",
    "#                 age_val_loss_items.append(age_loss)\n",
    "#                 age_val_acc_items.append(age_matches)\n",
    "#                 gender_val_loss_items.append(gender_loss)\n",
    "#                 gender_val_acc_items.append(gender_matches)\n",
    "#                 mask_val_loss_items.append(mask_loss)\n",
    "#                 mask_val_acc_items.append(mask_matches)\n",
    "\n",
    "#             age_val_loss = np.sum(age_val_loss_items) / len(val_loader)\n",
    "#             age_val_acc = np.sum(age_val_acc_items) / len(val_set)\n",
    "#             gender_val_loss = np.sum(gender_val_loss_items) / len(val_loader)\n",
    "#             gender_val_acc = np.sum(gender_val_acc_items) / len(val_set)\n",
    "#             mask_val_loss = np.sum(mask_val_loss_items) / len(val_loader)\n",
    "#             mask_val_acc = np.sum(mask_val_acc_items) / len(val_set)\n",
    "            \n",
    "#             age_best_val_loss = min(age_best_val_loss, age_val_loss)\n",
    "#             gender_best_val_loss = min(gender_best_val_loss, gender_val_loss)\n",
    "#             mask_best_val_loss = min(mask_best_val_loss, mask_val_loss)\n",
    "\n",
    "#             if age_val_acc > age_best_val_acc:\n",
    "#                 print(f\"New best model for val accuracy : {age_val_acc:4.2%}! saving the best model..\")\n",
    "#                 torch.save(model.module.state_dict(), f\"{save_dir}/best.pth\")\n",
    "#                 age_best_val_acc = age_val_acc\n",
    "#             torch.save(model.module.state_dict(), f\"{save_dir}/last.pth\")\n",
    "#             print(\n",
    "#                 f\"[Val] age acc : {age_val_acc:4.2%}, loss: {age_val_loss:4.2} || \"\n",
    "#                 f\"best acc : {age_best_val_acc:4.2%}, best loss: {age_best_val_loss:4.2}\"\n",
    "#             )\n",
    "#             print(\n",
    "#                 f\"[Val] gender acc : {gender_val_acc:4.2%}, loss: {gender_val_loss:4.2} || \"\n",
    "#                 f\"best acc : {gender_best_val_acc:4.2%}, best loss: {gender_best_val_loss:4.2}\"\n",
    "#             )\n",
    "#             print(\n",
    "#                 f\"[Val] mask acc : {mask_val_acc:4.2%}, loss: {mask_val_loss:4.2} || \"\n",
    "#                 f\"best acc : {mask_best_val_acc:4.2%}, best loss: {mask_best_val_loss:4.2}\"\n",
    "#             )\n",
    "\n",
    "#             wandb.log({'total_loss': total_loss, 'epoch': epoch})\n",
    "#             wandb.log({'age_val_accuracy': age_val_acc, 'age_val_loss': age_val_loss,'epoch': epoch})\n",
    "#             wandb.log({'gender_val_accuracy': gender_val_acc, 'gender_val_loss': gender_val_loss,'epoch': epoch})\n",
    "#             wandb.log({'mask_val_accuracy': mask_val_acc, 'mask_val_loss': mask_val_loss,'epoch': epoch})\n",
    "            \n",
    "#             print()\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     # Data and model checkpoints directories\n",
    "#     parser.add_argument('--seed', type=int, default=42, help='random seed (default: 42)')\n",
    "#     parser.add_argument('--epochs', type=int, default=30, help='number of epochs to train (default: 1)')\n",
    "#     parser.add_argument('--dataset', type=str, default='MaskSplitByProfileDataset', help='dataset augmentation type (default: MaskBaseDataset)')\n",
    "#     parser.add_argument('--augmentation', type=str, default='BaseAugmentation', help='data augmentation type (default: BaseAugmentation)')\n",
    "#     parser.add_argument(\"--resize\", nargs=\"+\", type=list, default=[128, 96], help='resize size for image when training')\n",
    "#     parser.add_argument('--batch_size', type=int, default=128, help='input batch size for training (default: 64)')\n",
    "#     parser.add_argument('--valid_batch_size', type=int, default=1000, help='input batch size for validing (default: 1000)')\n",
    "#     parser.add_argument('--model', type=str, default='BaseModel', help='model type (default: BaseModel)')\n",
    "#     parser.add_argument('--optimizer', type=str, default='Adam', help='optimizer type (default: SGD)')\n",
    "#     parser.add_argument('--lr', type=float, default=1e-4, help='learning rate (default: 1e-3)')\n",
    "#     parser.add_argument('--val_ratio', type=float, default=0.1, help='ratio for validaton (default: 0.2)')\n",
    "#     parser.add_argument('--criterion', type=str, default='focal', help='criterion type (default: cross_entropy)')\n",
    "#     parser.add_argument('--lr_decay_step', type=int, default=10, help='learning rate scheduler deacy step (default: 20)')\n",
    "#     parser.add_argument('--log_interval', type=int, default=20, help='how many batches to wait before logging training status')\n",
    "#     parser.add_argument('--name', default='exp', help='model save at {SM_MODEL_DIR}/{name}')\n",
    "\n",
    "#     # Container environment\n",
    "#     parser.add_argument('--data_dir', type=str, default=os.environ.get('SM_CHANNEL_TRAIN', '/opt/ml/input/data/train/images'))\n",
    "#     parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR', '/opt/ml/code/baseline/v2/model'))\n",
    "#     parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "#     print(args)\n",
    "\n",
    "#     data_dir = args.data_dir\n",
    "#     model_dir = args.model_dir\n",
    "\n",
    "#     train(data_dir, model_dir, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/10](20/630) || training loss 3.09 || training accuracy 12.29% || lr [0.0001]\n",
      "Epoch[0/10](40/630) || training loss 2.823 || training accuracy 19.79% || lr [0.0001]\n",
      "Epoch[0/10](60/630) || training loss 2.667 || training accuracy 19.79% || lr [0.0001]\n",
      "Epoch[0/10](80/630) || training loss 2.606 || training accuracy 24.17% || lr [0.0001]\n",
      "Epoch[0/10](100/630) || training loss 2.563 || training accuracy 26.25% || lr [0.0001]\n",
      "Epoch[0/10](120/630) || training loss 2.565 || training accuracy 25.42% || lr [0.0001]\n",
      "Epoch[0/10](140/630) || training loss 2.455 || training accuracy 27.92% || lr [0.0001]\n",
      "Epoch[0/10](160/630) || training loss 2.315 || training accuracy 29.58% || lr [0.0001]\n",
      "Epoch[0/10](180/630) || training loss 2.369 || training accuracy 30.00% || lr [0.0001]\n",
      "Epoch[0/10](200/630) || training loss 2.318 || training accuracy 32.50% || lr [0.0001]\n",
      "Epoch[0/10](220/630) || training loss 2.301 || training accuracy 31.25% || lr [0.0001]\n",
      "Epoch[0/10](240/630) || training loss 2.316 || training accuracy 31.46% || lr [0.0001]\n",
      "Epoch[0/10](260/630) || training loss 2.312 || training accuracy 28.12% || lr [0.0001]\n",
      "Epoch[0/10](280/630) || training loss 2.203 || training accuracy 35.42% || lr [0.0001]\n",
      "Epoch[0/10](300/630) || training loss 2.099 || training accuracy 36.25% || lr [0.0001]\n",
      "Epoch[0/10](320/630) || training loss 2.189 || training accuracy 35.62% || lr [0.0001]\n",
      "Epoch[0/10](340/630) || training loss 2.249 || training accuracy 32.92% || lr [0.0001]\n",
      "Epoch[0/10](360/630) || training loss 2.178 || training accuracy 33.96% || lr [0.0001]\n",
      "Epoch[0/10](380/630) || training loss 2.117 || training accuracy 37.50% || lr [0.0001]\n",
      "Epoch[0/10](400/630) || training loss 2.15 || training accuracy 32.50% || lr [0.0001]\n",
      "Epoch[0/10](420/630) || training loss 2.063 || training accuracy 35.42% || lr [0.0001]\n",
      "Epoch[0/10](440/630) || training loss 2.047 || training accuracy 36.88% || lr [0.0001]\n",
      "Epoch[0/10](460/630) || training loss 1.829 || training accuracy 44.38% || lr [0.0001]\n",
      "Epoch[0/10](480/630) || training loss 1.99 || training accuracy 39.79% || lr [0.0001]\n",
      "Epoch[0/10](500/630) || training loss 1.894 || training accuracy 42.08% || lr [0.0001]\n",
      "Epoch[0/10](520/630) || training loss 1.999 || training accuracy 33.54% || lr [0.0001]\n",
      "Epoch[0/10](540/630) || training loss 1.902 || training accuracy 37.50% || lr [0.0001]\n",
      "Epoch[0/10](560/630) || training loss 1.804 || training accuracy 44.79% || lr [0.0001]\n",
      "Epoch[0/10](580/630) || training loss 1.813 || training accuracy 44.79% || lr [0.0001]\n",
      "Epoch[0/10](600/630) || training loss 1.855 || training accuracy 45.62% || lr [0.0001]\n",
      "Epoch[0/10](620/630) || training loss 1.689 || training accuracy 49.38% || lr [0.0001]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 43.86%, loss:  4.1 || best acc : 43.86%, best loss:  4.1\n",
      "Epoch[1/10](20/630) || training loss 1.78 || training accuracy 43.75% || lr [0.0001]\n",
      "Epoch[1/10](40/630) || training loss 1.609 || training accuracy 47.08% || lr [0.0001]\n",
      "Epoch[1/10](60/630) || training loss 1.73 || training accuracy 47.50% || lr [0.0001]\n",
      "Epoch[1/10](80/630) || training loss 1.573 || training accuracy 51.04% || lr [0.0001]\n",
      "Epoch[1/10](100/630) || training loss 1.701 || training accuracy 47.08% || lr [0.0001]\n",
      "Epoch[1/10](120/630) || training loss 1.566 || training accuracy 48.75% || lr [0.0001]\n",
      "Epoch[1/10](140/630) || training loss 1.599 || training accuracy 49.38% || lr [0.0001]\n",
      "Epoch[1/10](160/630) || training loss 1.48 || training accuracy 53.54% || lr [0.0001]\n",
      "Epoch[1/10](180/630) || training loss 1.532 || training accuracy 51.46% || lr [0.0001]\n",
      "Epoch[1/10](200/630) || training loss 1.448 || training accuracy 52.92% || lr [0.0001]\n",
      "Epoch[1/10](220/630) || training loss 1.344 || training accuracy 56.67% || lr [0.0001]\n",
      "Epoch[1/10](240/630) || training loss 1.366 || training accuracy 56.67% || lr [0.0001]\n",
      "Epoch[1/10](260/630) || training loss 1.334 || training accuracy 56.04% || lr [0.0001]\n",
      "Epoch[1/10](280/630) || training loss 1.379 || training accuracy 55.83% || lr [0.0001]\n",
      "Epoch[1/10](300/630) || training loss 1.355 || training accuracy 56.88% || lr [0.0001]\n",
      "Epoch[1/10](320/630) || training loss 1.355 || training accuracy 56.46% || lr [0.0001]\n",
      "Epoch[1/10](340/630) || training loss 1.491 || training accuracy 54.79% || lr [0.0001]\n",
      "Epoch[1/10](360/630) || training loss 1.325 || training accuracy 56.04% || lr [0.0001]\n",
      "Epoch[1/10](380/630) || training loss 1.311 || training accuracy 56.88% || lr [0.0001]\n",
      "Epoch[1/10](400/630) || training loss 1.232 || training accuracy 60.42% || lr [0.0001]\n",
      "Epoch[1/10](420/630) || training loss 1.207 || training accuracy 59.79% || lr [0.0001]\n",
      "Epoch[1/10](440/630) || training loss 1.247 || training accuracy 61.04% || lr [0.0001]\n",
      "Epoch[1/10](460/630) || training loss 1.223 || training accuracy 62.29% || lr [0.0001]\n",
      "Epoch[1/10](480/630) || training loss 1.141 || training accuracy 59.58% || lr [0.0001]\n",
      "Epoch[1/10](500/630) || training loss 1.283 || training accuracy 57.92% || lr [0.0001]\n",
      "Epoch[1/10](520/630) || training loss 1.129 || training accuracy 62.50% || lr [0.0001]\n",
      "Epoch[1/10](540/630) || training loss 1.157 || training accuracy 63.12% || lr [0.0001]\n",
      "Epoch[1/10](560/630) || training loss 1.211 || training accuracy 61.25% || lr [0.0001]\n",
      "Epoch[1/10](580/630) || training loss 1.149 || training accuracy 62.29% || lr [0.0001]\n",
      "Epoch[1/10](600/630) || training loss 1.168 || training accuracy 59.79% || lr [0.0001]\n",
      "Epoch[1/10](620/630) || training loss 1.143 || training accuracy 61.88% || lr [0.0001]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 66.80%, loss:  1.5 || best acc : 66.80%, best loss:  1.5\n",
      "Epoch[2/10](20/630) || training loss 1.029 || training accuracy 66.67% || lr [0.0001]\n",
      "Epoch[2/10](40/630) || training loss 0.9773 || training accuracy 67.92% || lr [0.0001]\n",
      "Epoch[2/10](60/630) || training loss 0.9624 || training accuracy 65.62% || lr [0.0001]\n",
      "Epoch[2/10](80/630) || training loss 0.9664 || training accuracy 67.71% || lr [0.0001]\n",
      "Epoch[2/10](100/630) || training loss 0.914 || training accuracy 68.75% || lr [0.0001]\n",
      "Epoch[2/10](120/630) || training loss 1.01 || training accuracy 66.88% || lr [0.0001]\n",
      "Epoch[2/10](140/630) || training loss 0.9138 || training accuracy 67.50% || lr [0.0001]\n",
      "Epoch[2/10](160/630) || training loss 1.044 || training accuracy 66.88% || lr [0.0001]\n",
      "Epoch[2/10](180/630) || training loss 1.021 || training accuracy 65.42% || lr [0.0001]\n",
      "Epoch[2/10](200/630) || training loss 0.8907 || training accuracy 70.00% || lr [0.0001]\n",
      "Epoch[2/10](220/630) || training loss 0.8701 || training accuracy 70.62% || lr [0.0001]\n",
      "Epoch[2/10](240/630) || training loss 0.9275 || training accuracy 67.50% || lr [0.0001]\n",
      "Epoch[2/10](260/630) || training loss 0.8884 || training accuracy 70.62% || lr [0.0001]\n",
      "Epoch[2/10](280/630) || training loss 0.9145 || training accuracy 67.08% || lr [0.0001]\n",
      "Epoch[2/10](300/630) || training loss 0.8894 || training accuracy 70.21% || lr [0.0001]\n",
      "Epoch[2/10](320/630) || training loss 0.8713 || training accuracy 71.88% || lr [0.0001]\n",
      "Epoch[2/10](340/630) || training loss 0.9446 || training accuracy 67.50% || lr [0.0001]\n",
      "Epoch[2/10](360/630) || training loss 0.8137 || training accuracy 72.92% || lr [0.0001]\n",
      "Epoch[2/10](380/630) || training loss 0.8533 || training accuracy 71.88% || lr [0.0001]\n",
      "Epoch[2/10](400/630) || training loss 0.8744 || training accuracy 70.42% || lr [0.0001]\n",
      "Epoch[2/10](420/630) || training loss 0.8005 || training accuracy 72.08% || lr [0.0001]\n",
      "Epoch[2/10](440/630) || training loss 0.8308 || training accuracy 71.46% || lr [0.0001]\n",
      "Epoch[2/10](460/630) || training loss 0.758 || training accuracy 73.54% || lr [0.0001]\n",
      "Epoch[2/10](480/630) || training loss 0.8563 || training accuracy 72.08% || lr [0.0001]\n",
      "Epoch[2/10](500/630) || training loss 0.7842 || training accuracy 74.79% || lr [0.0001]\n",
      "Epoch[2/10](520/630) || training loss 0.899 || training accuracy 71.46% || lr [0.0001]\n",
      "Epoch[2/10](540/630) || training loss 0.7786 || training accuracy 73.33% || lr [0.0001]\n",
      "Epoch[2/10](560/630) || training loss 0.8313 || training accuracy 72.50% || lr [0.0001]\n",
      "Epoch[2/10](580/630) || training loss 0.7185 || training accuracy 77.50% || lr [0.0001]\n",
      "Epoch[2/10](600/630) || training loss 0.7548 || training accuracy 73.54% || lr [0.0001]\n",
      "Epoch[2/10](620/630) || training loss 0.6751 || training accuracy 79.79% || lr [0.0001]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 77.43%, loss: 0.86 || best acc : 77.43%, best loss: 0.86\n",
      "Epoch[3/10](20/630) || training loss 0.6162 || training accuracy 78.96% || lr [0.0001]\n",
      "Epoch[3/10](40/630) || training loss 0.6759 || training accuracy 76.67% || lr [0.0001]\n",
      "Epoch[3/10](60/630) || training loss 0.6513 || training accuracy 77.71% || lr [0.0001]\n",
      "Epoch[3/10](80/630) || training loss 0.6291 || training accuracy 78.12% || lr [0.0001]\n",
      "Epoch[3/10](100/630) || training loss 0.6454 || training accuracy 77.71% || lr [0.0001]\n",
      "Epoch[3/10](120/630) || training loss 0.6176 || training accuracy 78.96% || lr [0.0001]\n",
      "Epoch[3/10](140/630) || training loss 0.5173 || training accuracy 82.71% || lr [0.0001]\n",
      "Epoch[3/10](160/630) || training loss 0.6312 || training accuracy 79.17% || lr [0.0001]\n",
      "Epoch[3/10](180/630) || training loss 0.5468 || training accuracy 81.25% || lr [0.0001]\n",
      "Epoch[3/10](200/630) || training loss 0.595 || training accuracy 79.17% || lr [0.0001]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.join(os.getcwd(), 'results_0412', 'test'), exist_ok=True)\n",
    "\n",
    "counter = 0\n",
    "best_val_acc = 0\n",
    "num_epochs = 10\n",
    "accumulation_steps = 2\n",
    "train_log_interval = 20\n",
    "batch_size = 24\n",
    "patience = 1\n",
    "name = 'test'\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = m.to(device)\n",
    "best_val_loss = np.inf\n",
    "criterion = create_criterion('cross_entropy')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = StepLR(optimizer, 10, gamma=0.5)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=24,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=100,\n",
    "    num_workers=2,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # -- Gradient Accumulation\n",
    "        if (idx+1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        if (idx + 1) % train_log_interval == 0:\n",
    "            train_loss = loss_value / train_log_interval\n",
    "            train_acc = matches / batch_size / train_log_interval\n",
    "            current_lr = scheduler.get_last_lr()\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "            )\n",
    "\n",
    "            loss_value = 0\n",
    "            matches = 0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        for val_batch in val_loader:\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "\n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels == preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        val_acc = np.sum(val_acc_items) / len(val_dataset)\n",
    "        \n",
    "        # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        if val_acc > best_val_acc:\n",
    "            print(\"New best model for val accuracy! saving the model..\")\n",
    "            torch.save(model.state_dict(), f\"results/{name}/{epoch:03}_accuracy_{val_acc:4.2%}.ckpt\")\n",
    "            best_val_acc = val_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n",
    "        if counter > patience:\n",
    "            print(\"Early Stopping...\")\n",
    "            break\n",
    "        \n",
    "        print(\n",
    "            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "df95319d8ce4e1d89f5365ae10992bc1f65da593082b1d264e8f529830ec2f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
